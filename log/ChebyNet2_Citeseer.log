  NumNodes: 3327
  NumEdges: 9228
  NumFeats: 3703
  NumClasses: 6
  NumTrainingSamples: 120
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
Epoch: 0001 loss_train: 1.7941 acc_train: 0.1667 loss_val: 1.7949 acc_val: 0.0920 time: 0.0907s
Epoch: 0002 loss_train: 1.7913 acc_train: 0.1667 loss_val: 1.7931 acc_val: 0.0920 time: 0.0598s
Epoch: 0003 loss_train: 1.7856 acc_train: 0.1667 loss_val: 1.7899 acc_val: 0.0980 time: 0.0582s
Epoch: 0004 loss_train: 1.7777 acc_train: 0.2833 loss_val: 1.7866 acc_val: 0.2560 time: 0.0573s
Epoch: 0005 loss_train: 1.7669 acc_train: 0.4500 loss_val: 1.7826 acc_val: 0.3040 time: 0.0594s
Epoch: 0006 loss_train: 1.7553 acc_train: 0.5833 loss_val: 1.7777 acc_val: 0.4000 time: 0.0582s
Epoch: 0007 loss_train: 1.7468 acc_train: 0.6083 loss_val: 1.7721 acc_val: 0.4020 time: 0.0571s
Epoch: 0008 loss_train: 1.7317 acc_train: 0.6583 loss_val: 1.7659 acc_val: 0.3300 time: 0.0585s
Epoch: 0009 loss_train: 1.7027 acc_train: 0.6833 loss_val: 1.7587 acc_val: 0.3020 time: 0.0573s
Epoch: 0010 loss_train: 1.6935 acc_train: 0.7000 loss_val: 1.7510 acc_val: 0.3060 time: 0.0554s
Epoch: 0011 loss_train: 1.6747 acc_train: 0.6417 loss_val: 1.7423 acc_val: 0.3400 time: 0.0554s
Epoch: 0012 loss_train: 1.6447 acc_train: 0.7333 loss_val: 1.7327 acc_val: 0.3760 time: 0.0566s
Epoch: 0013 loss_train: 1.6082 acc_train: 0.7667 loss_val: 1.7222 acc_val: 0.4140 time: 0.0560s
Epoch: 0014 loss_train: 1.5880 acc_train: 0.7333 loss_val: 1.7104 acc_val: 0.4660 time: 0.0562s
Epoch: 0015 loss_train: 1.5520 acc_train: 0.7500 loss_val: 1.6978 acc_val: 0.5000 time: 0.0565s
Epoch: 0016 loss_train: 1.5264 acc_train: 0.8250 loss_val: 1.6843 acc_val: 0.5300 time: 0.0556s
Epoch: 0017 loss_train: 1.4817 acc_train: 0.8083 loss_val: 1.6702 acc_val: 0.5560 time: 0.0567s
Epoch: 0018 loss_train: 1.4455 acc_train: 0.8000 loss_val: 1.6552 acc_val: 0.5700 time: 0.0559s
Epoch: 0019 loss_train: 1.4139 acc_train: 0.8083 loss_val: 1.6396 acc_val: 0.5820 time: 0.0546s
Epoch: 0020 loss_train: 1.3975 acc_train: 0.8417 loss_val: 1.6230 acc_val: 0.6080 time: 0.0559s
Epoch: 0021 loss_train: 1.3338 acc_train: 0.8500 loss_val: 1.6058 acc_val: 0.6120 time: 0.0557s
Epoch: 0022 loss_train: 1.2776 acc_train: 0.8750 loss_val: 1.5885 acc_val: 0.6320 time: 0.0563s
Epoch: 0023 loss_train: 1.2308 acc_train: 0.8667 loss_val: 1.5708 acc_val: 0.6360 time: 0.0556s
Epoch: 0024 loss_train: 1.2165 acc_train: 0.8167 loss_val: 1.5525 acc_val: 0.6340 time: 0.0567s
Epoch: 0025 loss_train: 1.1635 acc_train: 0.9083 loss_val: 1.5335 acc_val: 0.6380 time: 0.0571s
Epoch: 0026 loss_train: 1.1438 acc_train: 0.8833 loss_val: 1.5143 acc_val: 0.6400 time: 0.0567s
Epoch: 0027 loss_train: 1.1039 acc_train: 0.8583 loss_val: 1.4952 acc_val: 0.6400 time: 0.0560s
Epoch: 0028 loss_train: 1.0408 acc_train: 0.8750 loss_val: 1.4759 acc_val: 0.6400 time: 0.0564s
Epoch: 0029 loss_train: 1.0307 acc_train: 0.8833 loss_val: 1.4563 acc_val: 0.6340 time: 0.0554s
Epoch: 0030 loss_train: 0.9760 acc_train: 0.9083 loss_val: 1.4368 acc_val: 0.6440 time: 0.0563s
Epoch: 0031 loss_train: 0.9132 acc_train: 0.9000 loss_val: 1.4173 acc_val: 0.6540 time: 0.0562s
Epoch: 0032 loss_train: 0.8648 acc_train: 0.9167 loss_val: 1.3984 acc_val: 0.6620 time: 0.0564s
Epoch: 0033 loss_train: 0.8821 acc_train: 0.9167 loss_val: 1.3797 acc_val: 0.6580 time: 0.0566s
Epoch: 0034 loss_train: 0.7970 acc_train: 0.9250 loss_val: 1.3609 acc_val: 0.6660 time: 0.0554s
Epoch: 0035 loss_train: 0.7463 acc_train: 0.9500 loss_val: 1.3436 acc_val: 0.6700 time: 0.0556s
Epoch: 0036 loss_train: 0.7278 acc_train: 0.9417 loss_val: 1.3273 acc_val: 0.6700 time: 0.0564s
Epoch: 0037 loss_train: 0.6982 acc_train: 0.9417 loss_val: 1.3115 acc_val: 0.6660 time: 0.0568s
Epoch: 0038 loss_train: 0.6529 acc_train: 0.9667 loss_val: 1.2964 acc_val: 0.6700 time: 0.0571s
Epoch: 0039 loss_train: 0.6626 acc_train: 0.9417 loss_val: 1.2814 acc_val: 0.6680 time: 0.0562s
Epoch: 0040 loss_train: 0.6172 acc_train: 0.9667 loss_val: 1.2668 acc_val: 0.6700 time: 0.0540s
Epoch: 0041 loss_train: 0.6307 acc_train: 0.9583 loss_val: 1.2528 acc_val: 0.6720 time: 0.0558s
Epoch: 0042 loss_train: 0.5826 acc_train: 0.9500 loss_val: 1.2394 acc_val: 0.6740 time: 0.0556s
Epoch: 0043 loss_train: 0.5694 acc_train: 0.9667 loss_val: 1.2264 acc_val: 0.6760 time: 0.0546s
Epoch: 0044 loss_train: 0.5358 acc_train: 0.9833 loss_val: 1.2144 acc_val: 0.6740 time: 0.0547s
Epoch: 0045 loss_train: 0.5572 acc_train: 0.9667 loss_val: 1.2026 acc_val: 0.6780 time: 0.0554s
Epoch: 0046 loss_train: 0.4906 acc_train: 0.9750 loss_val: 1.1913 acc_val: 0.6780 time: 0.0576s
Epoch: 0047 loss_train: 0.4823 acc_train: 0.9750 loss_val: 1.1810 acc_val: 0.6760 time: 0.0586s
Epoch: 0048 loss_train: 0.5059 acc_train: 0.9500 loss_val: 1.1722 acc_val: 0.6740 time: 0.0559s
Epoch: 0049 loss_train: 0.4634 acc_train: 0.9750 loss_val: 1.1646 acc_val: 0.6680 time: 0.0542s
Epoch: 0050 loss_train: 0.4460 acc_train: 0.9833 loss_val: 1.1571 acc_val: 0.6660 time: 0.0553s
Epoch: 0051 loss_train: 0.4576 acc_train: 0.9667 loss_val: 1.1490 acc_val: 0.6720 time: 0.0552s
Epoch: 0052 loss_train: 0.4827 acc_train: 0.9583 loss_val: 1.1415 acc_val: 0.6660 time: 0.0563s
Epoch: 0053 loss_train: 0.4472 acc_train: 0.9833 loss_val: 1.1344 acc_val: 0.6680 time: 0.0580s
Epoch: 0054 loss_train: 0.3995 acc_train: 0.9833 loss_val: 1.1278 acc_val: 0.6680 time: 0.0566s
Epoch: 0055 loss_train: 0.3843 acc_train: 0.9667 loss_val: 1.1210 acc_val: 0.6660 time: 0.0565s
Epoch: 0056 loss_train: 0.4010 acc_train: 0.9667 loss_val: 1.1143 acc_val: 0.6680 time: 0.0706s
Epoch: 0057 loss_train: 0.4226 acc_train: 0.9667 loss_val: 1.1085 acc_val: 0.6660 time: 0.0629s
Epoch: 0058 loss_train: 0.3871 acc_train: 0.9750 loss_val: 1.1040 acc_val: 0.6640 time: 0.0586s
Epoch: 0059 loss_train: 0.3843 acc_train: 0.9750 loss_val: 1.0991 acc_val: 0.6640 time: 0.0596s
Epoch: 0060 loss_train: 0.3977 acc_train: 0.9333 loss_val: 1.0949 acc_val: 0.6660 time: 0.0585s
Epoch: 0061 loss_train: 0.4095 acc_train: 0.9667 loss_val: 1.0903 acc_val: 0.6680 time: 0.0614s
Epoch: 0062 loss_train: 0.3221 acc_train: 1.0000 loss_val: 1.0861 acc_val: 0.6640 time: 0.0578s
Epoch: 0063 loss_train: 0.4179 acc_train: 0.9500 loss_val: 1.0821 acc_val: 0.6680 time: 0.0580s
Epoch: 0064 loss_train: 0.3978 acc_train: 0.9833 loss_val: 1.0783 acc_val: 0.6660 time: 0.0614s
Epoch: 0065 loss_train: 0.3407 acc_train: 0.9833 loss_val: 1.0751 acc_val: 0.6660 time: 0.0574s
Epoch: 0066 loss_train: 0.3538 acc_train: 0.9750 loss_val: 1.0718 acc_val: 0.6600 time: 0.0598s
Epoch: 0067 loss_train: 0.3574 acc_train: 0.9833 loss_val: 1.0689 acc_val: 0.6620 time: 0.0705s
Epoch: 0068 loss_train: 0.3354 acc_train: 0.9583 loss_val: 1.0656 acc_val: 0.6660 time: 0.0564s
Epoch: 0069 loss_train: 0.3294 acc_train: 0.9750 loss_val: 1.0624 acc_val: 0.6680 time: 0.0579s
Epoch: 0070 loss_train: 0.2752 acc_train: 1.0000 loss_val: 1.0594 acc_val: 0.6660 time: 0.0574s
Epoch: 0071 loss_train: 0.3853 acc_train: 0.9500 loss_val: 1.0574 acc_val: 0.6700 time: 0.0576s
Epoch: 0072 loss_train: 0.3065 acc_train: 1.0000 loss_val: 1.0552 acc_val: 0.6680 time: 0.0666s
Epoch: 0073 loss_train: 0.3075 acc_train: 0.9667 loss_val: 1.0545 acc_val: 0.6660 time: 0.0551s
Epoch: 0074 loss_train: 0.3495 acc_train: 0.9917 loss_val: 1.0537 acc_val: 0.6680 time: 0.0580s
Epoch: 0075 loss_train: 0.2960 acc_train: 0.9833 loss_val: 1.0523 acc_val: 0.6680 time: 0.0566s
Epoch: 0076 loss_train: 0.3253 acc_train: 0.9917 loss_val: 1.0481 acc_val: 0.6700 time: 0.0565s
Epoch: 0077 loss_train: 0.3155 acc_train: 0.9917 loss_val: 1.0430 acc_val: 0.6640 time: 0.0652s
Epoch: 0078 loss_train: 0.2665 acc_train: 0.9833 loss_val: 1.0396 acc_val: 0.6560 time: 0.0571s
Epoch: 0079 loss_train: 0.2544 acc_train: 0.9917 loss_val: 1.0364 acc_val: 0.6560 time: 0.0574s
Epoch: 0080 loss_train: 0.2501 acc_train: 1.0000 loss_val: 1.0334 acc_val: 0.6540 time: 0.0573s
Epoch: 0081 loss_train: 0.2873 acc_train: 0.9833 loss_val: 1.0313 acc_val: 0.6560 time: 0.0582s
Epoch: 0082 loss_train: 0.3018 acc_train: 0.9917 loss_val: 1.0293 acc_val: 0.6600 time: 0.0580s
Epoch: 0083 loss_train: 0.2496 acc_train: 1.0000 loss_val: 1.0285 acc_val: 0.6640 time: 0.0605s
Epoch: 0084 loss_train: 0.2652 acc_train: 0.9917 loss_val: 1.0295 acc_val: 0.6740 time: 0.0592s
Epoch: 0085 loss_train: 0.3273 acc_train: 1.0000 loss_val: 1.0289 acc_val: 0.6800 time: 0.0570s
Epoch: 0086 loss_train: 0.2899 acc_train: 0.9917 loss_val: 1.0269 acc_val: 0.6780 time: 0.0569s
Epoch: 0087 loss_train: 0.2837 acc_train: 0.9667 loss_val: 1.0238 acc_val: 0.6700 time: 0.0561s
Epoch: 0088 loss_train: 0.3214 acc_train: 0.9833 loss_val: 1.0198 acc_val: 0.6700 time: 0.0552s
Epoch: 0089 loss_train: 0.2467 acc_train: 0.9917 loss_val: 1.0159 acc_val: 0.6640 time: 0.0565s
Epoch: 0090 loss_train: 0.3469 acc_train: 0.9750 loss_val: 1.0131 acc_val: 0.6620 time: 0.0586s
Epoch: 0091 loss_train: 0.3099 acc_train: 0.9833 loss_val: 1.0106 acc_val: 0.6620 time: 0.0556s
Epoch: 0092 loss_train: 0.2935 acc_train: 0.9917 loss_val: 1.0083 acc_val: 0.6640 time: 0.0602s
Epoch: 0093 loss_train: 0.2470 acc_train: 0.9917 loss_val: 1.0063 acc_val: 0.6580 time: 0.0583s
Epoch: 0094 loss_train: 0.2616 acc_train: 0.9917 loss_val: 1.0053 acc_val: 0.6620 time: 0.0572s
Epoch: 0095 loss_train: 0.2951 acc_train: 0.9667 loss_val: 1.0042 acc_val: 0.6740 time: 0.0589s
Epoch: 0096 loss_train: 0.2802 acc_train: 0.9583 loss_val: 1.0032 acc_val: 0.6760 time: 0.0583s
Epoch: 0097 loss_train: 0.2320 acc_train: 1.0000 loss_val: 1.0020 acc_val: 0.6760 time: 0.0576s
Epoch: 0098 loss_train: 0.2292 acc_train: 0.9917 loss_val: 1.0004 acc_val: 0.6720 time: 0.0577s
Epoch: 0099 loss_train: 0.2660 acc_train: 0.9833 loss_val: 0.9985 acc_val: 0.6660 time: 0.0585s
Epoch: 0100 loss_train: 0.2772 acc_train: 0.9833 loss_val: 0.9959 acc_val: 0.6640 time: 0.0555s
Epoch: 0101 loss_train: 0.2654 acc_train: 0.9750 loss_val: 0.9938 acc_val: 0.6560 time: 0.0557s
Epoch: 0102 loss_train: 0.2868 acc_train: 0.9833 loss_val: 0.9928 acc_val: 0.6560 time: 0.0556s
Epoch: 0103 loss_train: 0.2333 acc_train: 0.9917 loss_val: 0.9912 acc_val: 0.6580 time: 0.0557s
Epoch: 0104 loss_train: 0.2641 acc_train: 0.9750 loss_val: 0.9901 acc_val: 0.6620 time: 0.0564s
Epoch: 0105 loss_train: 0.2057 acc_train: 0.9917 loss_val: 0.9898 acc_val: 0.6640 time: 0.0554s
Epoch: 0106 loss_train: 0.2230 acc_train: 0.9917 loss_val: 0.9889 acc_val: 0.6640 time: 0.0561s
Epoch: 0107 loss_train: 0.2253 acc_train: 1.0000 loss_val: 0.9884 acc_val: 0.6660 time: 0.0549s
Epoch: 0108 loss_train: 0.2572 acc_train: 0.9750 loss_val: 0.9884 acc_val: 0.6660 time: 0.0574s
Epoch: 0109 loss_train: 0.2428 acc_train: 0.9833 loss_val: 0.9878 acc_val: 0.6680 time: 0.0581s
Epoch: 0110 loss_train: 0.2579 acc_train: 0.9833 loss_val: 0.9869 acc_val: 0.6640 time: 0.0574s
Epoch: 0111 loss_train: 0.2374 acc_train: 0.9833 loss_val: 0.9852 acc_val: 0.6600 time: 0.0562s
Epoch: 0112 loss_train: 0.2103 acc_train: 1.0000 loss_val: 0.9823 acc_val: 0.6580 time: 0.0562s
Epoch: 0113 loss_train: 0.2244 acc_train: 0.9917 loss_val: 0.9800 acc_val: 0.6660 time: 0.0556s
Epoch: 0114 loss_train: 0.2213 acc_train: 1.0000 loss_val: 0.9795 acc_val: 0.6600 time: 0.0565s
Epoch: 0115 loss_train: 0.2046 acc_train: 1.0000 loss_val: 0.9795 acc_val: 0.6620 time: 0.0558s
Epoch: 0116 loss_train: 0.2690 acc_train: 0.9667 loss_val: 0.9799 acc_val: 0.6580 time: 0.0551s
Epoch: 0117 loss_train: 0.2229 acc_train: 0.9750 loss_val: 0.9789 acc_val: 0.6620 time: 0.0542s
Epoch: 0118 loss_train: 0.2395 acc_train: 0.9917 loss_val: 0.9779 acc_val: 0.6640 time: 0.0581s
Epoch: 0119 loss_train: 0.2177 acc_train: 0.9917 loss_val: 0.9773 acc_val: 0.6660 time: 0.0639s
Epoch: 0120 loss_train: 0.2095 acc_train: 0.9917 loss_val: 0.9768 acc_val: 0.6640 time: 0.0580s
Epoch: 0121 loss_train: 0.2337 acc_train: 0.9833 loss_val: 0.9765 acc_val: 0.6640 time: 0.0556s
Epoch: 0122 loss_train: 0.2222 acc_train: 0.9833 loss_val: 0.9762 acc_val: 0.6640 time: 0.0561s
Epoch: 0123 loss_train: 0.2708 acc_train: 0.9833 loss_val: 0.9753 acc_val: 0.6660 time: 0.0556s
Epoch: 0124 loss_train: 0.2216 acc_train: 0.9833 loss_val: 0.9740 acc_val: 0.6640 time: 0.0565s
Epoch: 0125 loss_train: 0.2175 acc_train: 1.0000 loss_val: 0.9726 acc_val: 0.6680 time: 0.0629s
Epoch: 0126 loss_train: 0.1637 acc_train: 1.0000 loss_val: 0.9722 acc_val: 0.6640 time: 0.0551s
Epoch: 0127 loss_train: 0.2215 acc_train: 0.9833 loss_val: 0.9717 acc_val: 0.6640 time: 0.0587s
Epoch: 0128 loss_train: 0.2342 acc_train: 0.9750 loss_val: 0.9710 acc_val: 0.6600 time: 0.0579s
Epoch: 0129 loss_train: 0.1949 acc_train: 0.9750 loss_val: 0.9694 acc_val: 0.6580 time: 0.0563s
Epoch: 0130 loss_train: 0.2281 acc_train: 0.9833 loss_val: 0.9682 acc_val: 0.6580 time: 0.0584s
Epoch: 0131 loss_train: 0.1957 acc_train: 0.9917 loss_val: 0.9667 acc_val: 0.6620 time: 0.0615s
Epoch: 0132 loss_train: 0.2301 acc_train: 0.9750 loss_val: 0.9656 acc_val: 0.6580 time: 0.0584s
Epoch: 0133 loss_train: 0.1755 acc_train: 0.9833 loss_val: 0.9650 acc_val: 0.6620 time: 0.0554s
Epoch: 0134 loss_train: 0.2212 acc_train: 1.0000 loss_val: 0.9649 acc_val: 0.6620 time: 0.0556s
Epoch: 0135 loss_train: 0.1848 acc_train: 0.9750 loss_val: 0.9645 acc_val: 0.6620 time: 0.0542s
Epoch: 0136 loss_train: 0.2095 acc_train: 0.9833 loss_val: 0.9640 acc_val: 0.6660 time: 0.0547s
Epoch: 0137 loss_train: 0.2695 acc_train: 0.9583 loss_val: 0.9632 acc_val: 0.6640 time: 0.0554s
Epoch: 0138 loss_train: 0.2651 acc_train: 0.9667 loss_val: 0.9631 acc_val: 0.6620 time: 0.0553s
Epoch: 0139 loss_train: 0.2119 acc_train: 0.9833 loss_val: 0.9637 acc_val: 0.6560 time: 0.0547s
Epoch: 0140 loss_train: 0.2046 acc_train: 0.9667 loss_val: 0.9635 acc_val: 0.6560 time: 0.0579s
Epoch: 0141 loss_train: 0.2171 acc_train: 0.9917 loss_val: 0.9623 acc_val: 0.6580 time: 0.0569s
Epoch: 0142 loss_train: 0.1922 acc_train: 0.9917 loss_val: 0.9611 acc_val: 0.6620 time: 0.0668s
Epoch: 0143 loss_train: 0.1876 acc_train: 0.9917 loss_val: 0.9606 acc_val: 0.6600 time: 0.0561s
Epoch: 0144 loss_train: 0.2302 acc_train: 0.9917 loss_val: 0.9596 acc_val: 0.6620 time: 0.0580s
Epoch: 0145 loss_train: 0.1759 acc_train: 0.9917 loss_val: 0.9599 acc_val: 0.6600 time: 0.0566s
Epoch: 0146 loss_train: 0.1834 acc_train: 1.0000 loss_val: 0.9607 acc_val: 0.6600 time: 0.0567s
Epoch: 0147 loss_train: 0.2137 acc_train: 0.9667 loss_val: 0.9619 acc_val: 0.6620 time: 0.0588s
Epoch: 0148 loss_train: 0.1630 acc_train: 1.0000 loss_val: 0.9627 acc_val: 0.6620 time: 0.0569s
Epoch: 0149 loss_train: 0.2064 acc_train: 1.0000 loss_val: 0.9627 acc_val: 0.6640 time: 0.0624s
Epoch: 0150 loss_train: 0.2122 acc_train: 1.0000 loss_val: 0.9619 acc_val: 0.6660 time: 0.0593s
Epoch: 0151 loss_train: 0.2186 acc_train: 0.9833 loss_val: 0.9613 acc_val: 0.6620 time: 0.0581s
Epoch: 0152 loss_train: 0.1811 acc_train: 0.9917 loss_val: 0.9601 acc_val: 0.6520 time: 0.0577s
Epoch: 0153 loss_train: 0.1948 acc_train: 0.9917 loss_val: 0.9573 acc_val: 0.6600 time: 0.0578s
Epoch: 0154 loss_train: 0.2008 acc_train: 0.9917 loss_val: 0.9540 acc_val: 0.6620 time: 0.0584s
Epoch: 0155 loss_train: 0.1786 acc_train: 0.9917 loss_val: 0.9521 acc_val: 0.6660 time: 0.0578s
Epoch: 0156 loss_train: 0.1719 acc_train: 0.9917 loss_val: 0.9511 acc_val: 0.6720 time: 0.0566s
Epoch: 0157 loss_train: 0.1989 acc_train: 0.9917 loss_val: 0.9509 acc_val: 0.6680 time: 0.0572s
Epoch: 0158 loss_train: 0.2358 acc_train: 0.9583 loss_val: 0.9510 acc_val: 0.6660 time: 0.0588s
Epoch: 0159 loss_train: 0.2206 acc_train: 0.9750 loss_val: 0.9509 acc_val: 0.6640 time: 0.0575s
Epoch: 0160 loss_train: 0.1670 acc_train: 0.9917 loss_val: 0.9518 acc_val: 0.6680 time: 0.0583s
Epoch: 0161 loss_train: 0.1711 acc_train: 0.9917 loss_val: 0.9530 acc_val: 0.6640 time: 0.0573s
Epoch: 0162 loss_train: 0.1893 acc_train: 1.0000 loss_val: 0.9529 acc_val: 0.6700 time: 0.0566s
Epoch: 0163 loss_train: 0.1718 acc_train: 0.9917 loss_val: 0.9508 acc_val: 0.6700 time: 0.0586s
Epoch: 0164 loss_train: 0.1853 acc_train: 0.9917 loss_val: 0.9493 acc_val: 0.6680 time: 0.0574s
Epoch: 0165 loss_train: 0.2002 acc_train: 0.9667 loss_val: 0.9472 acc_val: 0.6660 time: 0.0593s
Epoch: 0166 loss_train: 0.2172 acc_train: 0.9750 loss_val: 0.9459 acc_val: 0.6660 time: 0.0598s
Epoch: 0167 loss_train: 0.1770 acc_train: 1.0000 loss_val: 0.9445 acc_val: 0.6640 time: 0.0586s
Epoch: 0168 loss_train: 0.1551 acc_train: 1.0000 loss_val: 0.9442 acc_val: 0.6640 time: 0.0573s
Epoch: 0169 loss_train: 0.1736 acc_train: 0.9917 /Users/daizuocheng/Documents/localFiles/USYD/2023 Semester 1/SCDL3991/GCN_Simulation/utils.py:171: RuntimeWarning: divide by zero encountered in power
  r_inv = np.power(rowsum, -1).flatten()
loss_val: 0.9441 acc_val: 0.6640 time: 0.0565s
Epoch: 0170 loss_train: 0.1635 acc_train: 0.9917 loss_val: 0.9444 acc_val: 0.6660 time: 0.0588s
Epoch: 0171 loss_train: 0.1959 acc_train: 0.9750 loss_val: 0.9452 acc_val: 0.6640 time: 0.0567s
Epoch: 0172 loss_train: 0.1915 acc_train: 0.9833 loss_val: 0.9454 acc_val: 0.6620 time: 0.0581s
Epoch: 0173 loss_train: 0.1599 acc_train: 0.9917 loss_val: 0.9461 acc_val: 0.6620 time: 0.0581s
Epoch: 0174 loss_train: 0.1590 acc_train: 1.0000 loss_val: 0.9469 acc_val: 0.6660 time: 0.0562s
Epoch: 0175 loss_train: 0.2038 acc_train: 0.9833 loss_val: 0.9468 acc_val: 0.6660 time: 0.0558s
Epoch: 0176 loss_train: 0.1817 acc_train: 0.9750 loss_val: 0.9473 acc_val: 0.6680 time: 0.0565s
Epoch: 0177 loss_train: 0.1785 acc_train: 1.0000 loss_val: 0.9468 acc_val: 0.6680 time: 0.0562s
Epoch: 0178 loss_train: 0.1915 acc_train: 0.9917 loss_val: 0.9458 acc_val: 0.6660 time: 0.0564s
Epoch: 0179 loss_train: 0.1828 acc_train: 0.9833 loss_val: 0.9448 acc_val: 0.6640 time: 0.0579s
Epoch: 0180 loss_train: 0.1559 acc_train: 1.0000 loss_val: 0.9448 acc_val: 0.6680 time: 0.0564s
Epoch: 0181 loss_train: 0.2143 acc_train: 0.9583 loss_val: 0.9446 acc_val: 0.6700 time: 0.0560s
Epoch: 0182 loss_train: 0.1758 acc_train: 0.9917 loss_val: 0.9449 acc_val: 0.6720 time: 0.0556s
Epoch: 0183 loss_train: 0.1733 acc_train: 0.9917 loss_val: 0.9449 acc_val: 0.6680 time: 0.0578s
Epoch: 0184 loss_train: 0.1926 acc_train: 0.9833 loss_val: 0.9440 acc_val: 0.6620 time: 0.0565s
Epoch: 0185 loss_train: 0.1583 acc_train: 0.9917 loss_val: 0.9440 acc_val: 0.6620 time: 0.0558s
Epoch: 0186 loss_train: 0.1748 acc_train: 0.9917 loss_val: 0.9438 acc_val: 0.6620 time: 0.0562s
Epoch: 0187 loss_train: 0.1734 acc_train: 0.9750 loss_val: 0.9440 acc_val: 0.6620 time: 0.0558s
Epoch: 0188 loss_train: 0.1584 acc_train: 0.9917 loss_val: 0.9433 acc_val: 0.6640 time: 0.0571s
Epoch: 0189 loss_train: 0.1848 acc_train: 0.9917 loss_val: 0.9415 acc_val: 0.6560 time: 0.0585s
Epoch: 0190 loss_train: 0.2111 acc_train: 0.9833 loss_val: 0.9403 acc_val: 0.6620 time: 0.0576s
Epoch: 0191 loss_train: 0.1639 acc_train: 1.0000 loss_val: 0.9404 acc_val: 0.6640 time: 0.0562s
Epoch: 0192 loss_train: 0.1962 acc_train: 0.9833 loss_val: 0.9397 acc_val: 0.6600 time: 0.0554s
Epoch: 0193 loss_train: 0.2083 acc_train: 0.9750 loss_val: 0.9389 acc_val: 0.6600 time: 0.0572s
Epoch: 0194 loss_train: 0.1396 acc_train: 1.0000 loss_val: 0.9382 acc_val: 0.6580 time: 0.0561s
Epoch: 0195 loss_train: 0.1504 acc_train: 1.0000 loss_val: 0.9384 acc_val: 0.6580 time: 0.0558s
Epoch: 0196 loss_train: 0.1838 acc_train: 0.9750 loss_val: 0.9386 acc_val: 0.6580 time: 0.0557s
Epoch: 0197 loss_train: 0.1643 acc_train: 0.9917 loss_val: 0.9389 acc_val: 0.6620 time: 0.0564s
Epoch: 0198 loss_train: 0.1652 acc_train: 0.9833 loss_val: 0.9391 acc_val: 0.6660 time: 0.0547s
Epoch: 0199 loss_train: 0.1521 acc_train: 1.0000 loss_val: 0.9403 acc_val: 0.6660 time: 0.0612s
Epoch: 0200 loss_train: 0.1916 acc_train: 0.9750 loss_val: 0.9418 acc_val: 0.6600 time: 0.0567s
Optimization Finished on citeseer!
Model: chebynet
2 layers ChebyNet with 2-th order Chebyshev Polynomial
Total time elapsed: 11.6936s
Test set results: loss= 0.9656 accuracy= 0.6850
